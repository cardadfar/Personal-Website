{
  "key": {
    "t": "title",
    "s": "subtitle",
    "i": "img",
    "d": "img description",
    "p": "text"
  },

  "t_0": "How Far We've Come.",
  "p_1": "I developed AR Typography, a mobile app that delivers real-time text motion tracking to video, allowing for the creation of immerse, real-life kinetic typography videos for any videographer.",
  "i_2": "how-far-weve-come/cover.png",
  "d_2": "A mobile app that delivers real-time text motion tracking to video",
  "p_3": "AR Typography places text anywhere based on a simple touch of the screen. Built on AR Core in Unity, people can place multiple layers of 3D text, each with their own unique content, into one environment. The text tracks changes in movement, and will maintain its position and rotation values when moving around.",
  "s_4": "How It Works",
  "p_5": "AR Typography is able to generate 3D text onto flat surfaces (including walls) by intercepting the point cloud data from AR core and creating independent tracking planes for each object at the point the screen was tapped. When tapping the screen, the app will project the active 3D point cloud data (active referring to points visible to the camera) onto a 2D surface and find the closest point to where the screen was touched. Iterating over the point cloud data, this point will find the next two closest point in order to find the best cross product that represents the orientation of the point. The point now contains information about the position and orientation that can be used to generate the text.",
  "i_6": "how-far-weve-come/demo.jpg",
  "d_6": "Use of AR Typography to place 3D text in 3D space",
  "p_6": "AR Typography loads multiple strings of text into a list upon startup. The active text will modulate over the list of strings and generate a text object with the contents of the active text. This allows for effective storage and placement of multiple pieces of text in one scene.",
  "i_7": "how-far-weve-come/scripting-01.png",
  "d_7": "Loading in multiple strings on startup",
  "p_8": "In an effort to be able to film shots better without interruptions, I removed the point cloud and tracking plane visualizations.",
  "p_9": "In order to create a 3D effect for the text, a white text layer is placed at position p with orientation r, and 15 additional iterations of black text is placed at position (p â€“ (i+1)*k*r) and orientation r, where i is the index [0,14] and k is some constant.",
  "i_10": "how-far-weve-come/text-01.jpg",
  "d_10": "Placing hard drop shadows onto text by creating multiple black objects behind them",
  "s_11": "Rendering Environments",
  "p_12": "Using AR Core for Unity, I wrote the script TextCore to handle text placement and adjustment.",
  "i_12": "how-far-weve-come/scripting-02.png",
  "d_12": "Scripting environment using AR Core documentation",
  "p_13": "I generated an additional 2.5D text layer and set it as a global public parameter for TextCore. Whenever the screen was tapped, TextCore would generate a copy of the text layer at position p with orientation r, followed by successive text layers with black fills for a drop shadow effect. The contents of the text layer would also be changed to match the next string loaded into TextCore from startup.",
  "i_13": "how-far-weve-come/unity.png",
  "d_13": "Creating text objects in the Unity environment",
  "p_14": "To demonstrate AR Core, I went around campus filming shots of me placing text around the area. Since it was in the Unity app, I could not use the built in camera feature, and had to use the external screen recording app AZ Recorder. I compiled the footage in After Effects with additional found footage at the end.",
  "i_15": "how-far-weve-come/after-effects.jpg",
  "d_15": "Composing footage in After Effects"
}
